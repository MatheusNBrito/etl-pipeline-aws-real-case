{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "46793228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, when, isnull, lit, length, explode, count, upper, lower, regexp_replace, regexp_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2e0c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# enableVectorizedReader is set to false to avoid issues with certain Parquet files\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Data quality check vendas\") \\\n",
    "    .config(\"spark.sql.parquet.enableVectorizedReader\", \"false\") \\\n",
    "    .config(\"spark.hadoop.io.nativeio\", \"false\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fa1826e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"/app/data/raw/vendas.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9224d94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- d_dt_vd: timestamp (nullable = true)\n",
      " |-- n_id_fil: long (nullable = true)\n",
      " |-- n_id_vd_fil: long (nullable = true)\n",
      " |-- v_cli_cod: string (nullable = true)\n",
      " |-- n_vlr_tot_vd: decimal(18,6) (nullable = true)\n",
      " |-- n_vlr_tot_desc: decimal(14,4) (nullable = true)\n",
      " |-- v_cpn_eml: string (nullable = true)\n",
      " |-- tp_pgt: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "757d7b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+-----------+--------------------+------------+--------------+---------+-------+\n",
      "|            d_dt_vd|n_id_fil|n_id_vd_fil|           v_cli_cod|n_vlr_tot_vd|n_vlr_tot_desc|v_cpn_eml| tp_pgt|\n",
      "+-------------------+--------+-----------+--------------------+------------+--------------+---------+-------+\n",
      "|2023-10-13 00:00:00| 2356284|34366442231|016E6FCC4F98832719BC|   55.960000|       13.9900|      NAO|A VISTA|\n",
      "|2023-10-13 00:00:00| 2221184|35550863931|035D148EADC74B6C6D2F|   31.480000|       25.2100|      NAO|   NULL|\n",
      "|2023-10-28 00:00:00| 2188984|37392732531|030C1011214A3317E850|    6.490000|       13.1400|      NAO|A VISTA|\n",
      "|2023-10-09 00:00:00| 2608284| 3672652731|04710AFAF1FD9C48EBC3|   52.990000|       40.2700|      NAO|   NULL|\n",
      "|2023-10-10 00:00:00|  238084|37059405031|028DBA5BBB05DDF47E4C|   18.540000|        8.3800|      NAO|A VISTA|\n",
      "+-------------------+--------+-----------+--------------------+------------+--------------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "48bfe6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:====================================================>   (17 + 1) / 18]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----------+---------+------------+--------------+---------+-------+\n",
      "|d_dt_vd|n_id_fil|n_id_vd_fil|v_cli_cod|n_vlr_tot_vd|n_vlr_tot_desc|v_cpn_eml| tp_pgt|\n",
      "+-------+--------+-----------+---------+------------+--------------+---------+-------+\n",
      "|      0|       0|          0|  5206154|           0|             0|        0|5268260|\n",
      "+-------+--------+-----------+---------+------------+--------------+---------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select([\n",
    "    count(when(isnull(c), c)).alias(c) for c in df.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eae272",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (etl-pipeline-aws)",
   "language": "python",
   "name": "etl-pipeline-aws"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
